{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ArabicSpeech Training.ipynb","provenance":[],"authorship_tag":"ABX9TyOX0CKB6OjqlSS1SRl1GUEz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AG00jWSm99WJ","executionInfo":{"status":"ok","timestamp":1630578836544,"user_tz":-300,"elapsed":710,"user":{"displayName":"Alina Baber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjUgi6JqEc9C1vG1gVI7wEF-7eOnos1u859PjcqZg=s64","userId":"07016951716642667333"}},"outputId":"46c96806-9a62-4bda-d328-32d2c0164be9"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdnBLIra-Epk","executionInfo":{"status":"ok","timestamp":1630577287841,"user_tz":-300,"elapsed":2844,"user":{"displayName":"Alina Baber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjUgi6JqEc9C1vG1gVI7wEF-7eOnos1u859PjcqZg=s64","userId":"07016951716642667333"}},"outputId":"907e2a67-51da-4ab4-ce04-13960d02a135"},"source":["!pip install spafe joblib\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spafe in /usr/local/lib/python3.7/dist-packages (0.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.19.5)\n","Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from spafe) (1.4.1)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement scikitplot (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for scikitplot\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"EJxnCI3393bK","executionInfo":{"status":"error","timestamp":1630578732055,"user_tz":-300,"elapsed":506,"user":{"displayName":"Alina Baber","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjUgi6JqEc9C1vG1gVI7wEF-7eOnos1u859PjcqZg=s64","userId":"07016951716642667333"}},"outputId":"79bce302-9854-4a4c-e322-c8ed8b80a2de"},"source":["\n","\n","#Importing Libraries\n","from collections import Counter\n","\n","import numpy as np\n","import pandas as pd\n","import os, sys\n","import matplotlib.pyplot as plt\n","import librosa\n","#import scikitplot as skplt\n","from spafe.features.lpc import lpc, lpcc\n","from spafe.features.rplp import rplp, plp\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n","from sklearn.metrics import accuracy_score\n","from sklearn import metrics\n","from sklearn.svm import SVC\n","from sklearn import preprocessing\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","import warnings\n","import joblib\n","import seaborn as sns\n","#import features as fs\n","from sklearn.metrics import r2_score\n","from scipy import stats\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import classification_report\n","def mfcc_feature(audio, sample_rate):\n","    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n"," \n","    return mfcc   # it returns a np.array with size (40,'n') where n is the number of audio frames.\n","\n","def melspectrogram_feature(audio, sample_rate):\n","    melspectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=2048)\n"," \n","    return melspectrogram   # it returns a np.array with size (128,'n') where n is the number of audio frames.\n","\n","def poly_feature(audio, sample_rate):\n","    poly_features = librosa.feature.poly_features(y=audio, sr=sample_rate, n_fft=2048)\n"," \n","    return poly_features   # it returns a np.array with size (2,'n') where n is the number of audio frames.\n","\n","def zero_crossing_rate_features(audio):\n","    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)\n"," \n","    return zero_crossing_rate   # it returns a np.array with size (1,'n') where n is the number of audio frames.\n","\n","\n","def normalize(data):\n","  data = (data-min(data))/(max(data)-min(data))\n","  \n","  return data\n","\n","\n","def results(target_test, predicted_test,ModelName,labels):\n","    target_names = labels\n","    print(classification_report(target_test, y_predd1, target_names=target_names))\n","    y_test = target_test\n","    preds = predicted_test\n","    rms = np.sqrt(np.mean(np.power((np.array(y_test) - np.array(preds)), 2)))\n","    score = r2_score(y_test, preds)\n","    mae = mean_absolute_error(y_test, preds)\n","    mse = mean_squared_error(y_test, preds)\n","    pearson_coef, p_value = stats.pearsonr(y_test, preds)\n","\n","    print(\"root mean square:\", rms)\n","    print(\"score:\", score)\n","    print(\"mean absolute error:\", mae)\n","    print(\"mean squared error:\", mse)\n","    print(\"pearson_coef:\", pearson_coef)\n","    print(\"p_value:\", p_value)\n","    print(\"=======================================================================\\n\\n\")\n","    skplt.metrics.plot_confusion_matrix(\n","        y_test,\n","        preds,\n","        figsize=(10, 6), title=\"Confusion matrix\\n Deposite Category \"+ModelName)\n","    plt.xlim(-0.5, len(np.unique(y_test)) - 0.5)\n","    plt.ylim(len(np.unique(y_test)) - 0.5, -0.5)\n","    plt.savefig('cvroc.png')\n","    plt.show()\n","warnings.filterwarnings('ignore')\n","\n","# setting the path where all file's folder are\n","\n","root = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\Al-Kawthar\\\\'\n","\n","Features_data = pd.DataFrame(columns=['features','class']) \n","\n","i = 0\n","sample_rate = 16000 \n","no_of_samples = 300\n","MainFolder=\"Al-Kawthar\"\n","labels=os.listdir(MainFolder)\n","\n","\n","# Loading the features in the dataframe\n","for label in labels:\n","  \n","  print(label)\n","  folders = os.path.join(root,label)\n","  items = os.listdir(folders)\n","\n","  for item in items[:no_of_samples]:\n","\n","    path = os.path.join(folders,item)\n","\n","    #Convert .wave into array\n","    samples, sample_rate=librosa.load(path ,sr=sample_rate)\n","\n","    #Extract Feautures\n","    MFCC = mfcc_feature(samples , sample_rate)\n","    MSS = melspectrogram_feature(samples , sample_rate)\n","    poly = poly_feature(samples , sample_rate)\n","    ZCR = zero_crossing_rate_features(samples)\n","\n","    # flatten an array\n","    MFCC = MFCC.flatten()\n","    MSS = MSS.flatten()\n","    poly = poly.flatten()\n","    ZCR = ZCR.flatten()\n","\n","    # normalizing\n","    # MFCC = normalize(MFCC)\n","\n","    features = np.concatenate(( MFCC ,MSS, poly, ZCR))\n","\n","    # padding and trimming\n","    max_len = 6000\n","\n","    pad_width = max_len - features.shape[0]\n","    if pad_width > 0:\n","      features = np.pad(features, pad_width=((0, pad_width)), mode='constant')\n","\n","    features = features[:max_len]\n","\n","    Features_data.loc[i] =[features, label]\n","    i += 1\n","np.set_printoptions(threshold=sys.maxsize)\n","feature=np.array(Features_data['features'].tolist())\n","target = Features_data.iloc[:,-1]\n","# converting labels into numeric\n","le = preprocessing.LabelEncoder()\n","target=le.fit_transform(target)\n","# features = preprocessing.MinMaxScaler().fit_transform(features)\n","feature_train, feature_test, target_train, target_test = train_test_split(feature,target)\n","#Create a Gaussian Classifier\n","clff=RandomForestClassifier(n_estimators=800)\n","#Train the model using the training sets y_pred=clf.predict(X_test)\n","clff = clff.fit(feature_train,target_train)\n","y_predd1=clff.predict(feature_test)\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Random Forest Accuracy:\",metrics.accuracy_score(target_test, y_predd1))\n","results(target_test, y_predd1,\"Random Forest\",labels)\n","\n","target_names = labels\n","\n","sns.heatmap(confusion_matrix(target_test,y_predd1), annot=True, cmap='Blues')\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(clff, model_path+\"model_3000.sav\")\n","#Create a KNN Classifier\n","knn=KNeighborsClassifier()\n","#Train the model using the training sets y_pred=clf.predict(X_test)\n","knn = knn.fit(feature_train,target_train)\n","y_predd2=knn.predict(feature_test)\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Accuracy KNN:\",metrics.accuracy_score(target_test, y_predd2))\n","results(target_test, y_predd2,\"KNN\",labels)\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(knn, model_path+\"model_knn.sav\")\n","# training a linear SVM classifier\n","svm_model_linear = SVC(kernel = 'linear', C = 1).fit(feature_train,target_train)\n","y_predd3 = svm_model_linear.predict(feature_test)\n","# model accuracy for X_test\n","accuracy = svm_model_linear.score(feature_test, target_test)\n","print(\"Accuracy SVM:\",metrics.accuracy_score(target_test, y_predd3))\n","results(target_test, y_predd3,\"SVM\",labels)\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(svm_model_linear, model_path+\"model_svm.sav\")\n","model1 = RandomForestClassifier()\n","model2 = KNeighborsClassifier()\n","model3 = LogisticRegression()\n","Voting = VotingClassifier(estimators=[('RF', model1 ), ('knn', model2),('lr',model3)], voting='hard')\n","Voting.fit(feature_train,target_train)\n","vpredictions = Voting.predict(feature_test)\n","vscore = Voting.score(feature_test, target_test)\n","print(\"Voting Score\", vscore)\n","results(target_test, vpredictions,\"Voting Classifier\",labels)\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(Voting, model_path+\"model_voting.sav\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-533e10fc7fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mno_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mMainFolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Al-Kawthar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMainFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Al-Kawthar'"]}]},{"cell_type":"code","metadata":{"id":"lttQ0I6iGe3c"},"source":["\n","\n","#Importing Libraries\n","from collections import Counter\n","\n","import numpy as np\n","import pandas as pd\n","import os, sys\n","import matplotlib.pyplot as plt\n","import librosa\n","import scikitplot as skplt\n","from spafe.features.lpc import lpc, lpcc\n","from spafe.features.rplp import rplp, plp\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n","from sklearn.metrics import accuracy_score\n","from sklearn import metrics\n","from sklearn.svm import SVC\n","from sklearn import preprocessing\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","import warnings\n","import joblib\n","import seaborn as sns\n","import features as fs\n","from sklearn.metrics import r2_score\n","from scipy import stats\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import classification_report\n","def mfcc_feature(audio, sample_rate):\n","    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n"," \n","    return mfcc   # it returns a np.array with size (40,'n') where n is the number of audio frames.\n","\n","def melspectrogram_feature(audio, sample_rate):\n","    melspectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=2048)\n"," \n","    return melspectrogram   # it returns a np.array with size (128,'n') where n is the number of audio frames.\n","\n","def poly_feature(audio, sample_rate):\n","    poly_features = librosa.feature.poly_features(y=audio, sr=sample_rate, n_fft=2048)\n"," \n","    return poly_features   # it returns a np.array with size (2,'n') where n is the number of audio frames.\n","\n","def zero_crossing_rate_features(audio):\n","    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)\n"," \n","    return zero_crossing_rate   # it returns a np.array with size (1,'n') where n is the number of audio frames.\n","\n","\n","def normalize(data):\n","  data = (data-min(data))/(max(data)-min(data))\n","  \n","  return data\n","\n","\n","def results(target_test, predicted_test,ModelName,labels):\n","    target_names = labels\n","    print(classification_report(target_test, y_predd1, target_names=target_names))\n","    y_test = target_test\n","    preds = predicted_test\n","    rms = np.sqrt(np.mean(np.power((np.array(y_test) - np.array(preds)), 2)))\n","    score = r2_score(y_test, preds)\n","    mae = mean_absolute_error(y_test, preds)\n","    mse = mean_squared_error(y_test, preds)\n","    pearson_coef, p_value = stats.pearsonr(y_test, preds)\n","\n","    print(\"root mean square:\", rms)\n","    print(\"score:\", score)\n","    print(\"mean absolute error:\", mae)\n","    print(\"mean squared error:\", mse)\n","    print(\"pearson_coef:\", pearson_coef)\n","    print(\"p_value:\", p_value)\n","    print(\"=======================================================================\\n\\n\")\n","    skplt.metrics.plot_confusion_matrix(\n","        y_test,\n","        preds,\n","        figsize=(10, 6), title=\"Confusion matrix\\n Deposite Category \"+ModelName)\n","    plt.xlim(-0.5, len(np.unique(y_test)) - 0.5)\n","    plt.ylim(len(np.unique(y_test)) - 0.5, -0.5)\n","    plt.savefig('cvroc.png')\n","    plt.show()\n","warnings.filterwarnings('ignore')\n","\n","# setting the path where all file's folder are\n","\n","root = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api - Copy (2)\\\\worddataset\\\\'\n","\n","Features_data = pd.DataFrame(columns=['features','class']) \n","\n","i = 0\n","sample_rate = 16000 \n","no_of_samples = 300\n","MainFolder=\"worddataset\"\n","labels=os.listdir(MainFolder)\n","\n","\n","# Loading the features in the dataframe\n","for label in labels:\n","  \n","  print(label)\n","  folders = os.path.join(root,label)\n","  items = os.listdir(folders)\n","\n","  for item in items[:no_of_samples]:\n","\n","    path = os.path.join(folders,item)\n","\n","    #Convert .wave into array\n","    samples, sample_rate=librosa.load(path ,sr=sample_rate)\n","\n","    #Extract Feautures\n","    MFCC = mfcc_feature(samples , sample_rate)\n","    MSS = melspectrogram_feature(samples , sample_rate)\n","    poly = poly_feature(samples , sample_rate)\n","    ZCR = zero_crossing_rate_features(samples)\n","\n","    # flatten an array\n","    MFCC = MFCC.flatten()\n","    MSS = MSS.flatten()\n","    poly = poly.flatten()\n","    ZCR = ZCR.flatten()\n","\n","    # normalizing\n","    # MFCC = normalize(MFCC)\n","\n","    features = np.concatenate(( MFCC ,MSS, poly, ZCR))\n","\n","    # padding and trimming\n","    max_len = 6000\n","\n","    pad_width = max_len - features.shape[0]\n","    if pad_width > 0:\n","      features = np.pad(features, pad_width=((0, pad_width)), mode='constant')\n","\n","    features = features[:max_len]\n","\n","    Features_data.loc[i] =[features, label]\n","    i += 1\n","np.set_printoptions(threshold=sys.maxsize)\n","feature=np.array(Features_data['features'].tolist())\n","target = Features_data.iloc[:,-1]\n","# converting labels into numeric\n","le = preprocessing.LabelEncoder()\n","target=le.fit_transform(target)\n","# features = preprocessing.MinMaxScaler().fit_transform(features)\n","feature_train, feature_test, target_train, target_test = train_test_split(feature,target)\n","#Create a Gaussian Classifier\n","clff=RandomForestClassifier(n_estimators=800)\n","#Train the model using the training sets y_pred=clf.predict(X_test)\n","clff = clff.fit(feature_train,target_train)\n","y_predd1=clff.predict(feature_test)\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Random Forest Accuracy:\",metrics.accuracy_score(target_test, y_predd1))\n","results(target_test, y_predd1,\"Random Forest\",labels)\n","\n","target_names = labels\n","\n","sns.heatmap(confusion_matrix(target_test,y_predd1), annot=True, cmap='Blues')\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(clff, model_path+\"model_3000words.sav\")\n","#Create a KNN Classifier\n","knn=KNeighborsClassifier()\n","#Train the model using the training sets y_pred=clf.predict(X_test)\n","knn = knn.fit(feature_train,target_train)\n","y_predd2=knn.predict(feature_test)\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Accuracy KNN:\",metrics.accuracy_score(target_test, y_predd2))\n","results(target_test, y_predd2,\"KNN\",labels)\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(knn, model_path+\"model_knnwords.sav\")\n","# training a linear SVM classifier\n","svm_model_linear = SVC(kernel = 'linear', C = 1).fit(feature_train,target_train)\n","y_predd3 = svm_model_linear.predict(feature_test)\n","# model accuracy for X_test\n","accuracy = svm_model_linear.score(feature_test, target_test)\n","print(\"Accuracy SVM:\",metrics.accuracy_score(target_test, y_predd3))\n","results(target_test, y_predd3,\"SVM\",labels)\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(svm_model_linear, model_path+\"model_svmwords.sav\")\n","model1 = RandomForestClassifier()\n","model2 = KNeighborsClassifier()\n","model3 = LogisticRegression()\n","Voting = VotingClassifier(estimators=[('RF', model1 ), ('knn', model2),('lr',model3)], voting='hard')\n","Voting.fit(feature_train,target_train)\n","vpredictions = Voting.predict(feature_test)\n","vscore = Voting.score(feature_test, target_test)\n","print(\"Voting Score\", vscore)\n","results(target_test, vpredictions,\"Voting Classifier\",labels)\n","model_path = 'C:\\\\Users\\\\Alina Baber\\\\projects\\\\api\\\\content\\\\'\n","joblib.dump(Voting, model_path+\"model_votingwords.sav\")"],"execution_count":null,"outputs":[]}]}